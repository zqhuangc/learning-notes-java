分库降低了单点机器的负载；分表，提高了数据操作的效率，尤其是Write操作的效率

数据切分可以是物理上的，对数据通过一系列的切分规则将数据分布到不同的DB服务器上，通过路由规则路由访问特定的数据库，这样一来每次访问面对的就不是单台服务器了，而是N台服务器，这样就可以降低单台机器的负载压力。
数据切分也可以是数据库内的 ，对数据通过一系列的切分规则，将数据分布到一个数据库的不同表 中，比如将article分为article_001,article_002等子表，若干个子表水平拼合有组成了逻辑上一个完整的article表，这 样做的目的其实也是很简单的。 

## 三种分库的方式和规则
按号段分：  
(1) user_id为区分，1～1000的对应DB1，1001～2000的对应DB2，以此类推；  
- 优点：可部分迁移  
- 缺点：数据分布不均

(2)hash取模分：  
对user_id进行hash（或者如果user_id是数值型的话直接使用user_id 的值也可），然后用一个特定的数字，比如应用中需要将一个数据库切分成4个数据库的话，我们就用4这个数字对user_id的hash值进行取模运算，也 就是user_id%4,这样的话每次运算就有四种可能：结果为1的时候对应DB1；结果为2的时候对应DB2；结果为3的时候对应DB3；结果为0的时 候对应DB4，这样一来就非常均匀的将数据分配到4个DB中。  
- 优点：数据分布均匀  
- 缺点：数据迁移的时候麻烦，不能按照机器性能分摊数据 

(3)在认证库中保存数据库配置  
就是建立一个DB，这个DB单独保存user_id到DB的映射关系，每次访问数据库的时候都要先查询一次这个数据库，以得到具体的DB信息，然后才能进行我们需要的查询操作。
- 优点：灵活性强，一对一关系
- 缺点：每次查询之前都要多一次查询，性能大打折扣

#### 分布式数据方案提供功能如下：
（1）提供分库规则和路由规则（RouteRule简称RR），将上面的说明中提到的三中切分规则直接内嵌入本系统，具体的嵌入方式在接下来的内容中进行详细的说明和论述；  
（2）引入集群（Group）的概念，保证数据的高可用性；  
（3）引入负载均衡策略（LoadBalancePolicy简称LB）；  
（4）引入集群节点可用性探测机制，对单点机器的可用性进行定时的侦测，以保证LB策略的正确实施，以确保系统的高度稳定性；  
（5）引入读/写分离，提高数据的查询速度；

容错性



 

 

 

## 为什么要分库分表?

超大容量问题

性能问题

## 如何去做到

垂直切分、 水平切分

* 垂直切分

1. 垂直分库：解决的是表过多的问题

2. 垂直分表：解决单表列过多的问题 

* 水平切分：大数据表拆成小表

## 常见的拆分策略

垂直拆分（er分片）

 

水平拆分

一致性hash

范围切分 可以按照ID

日期拆分

## 拆分以后带来的问题

### 跨库join的问题

1. 设计的时候考虑到应用层的 join 问题。（跨库、数据源不同）

2. 在服务层去做调用；
   A服务里查询到一个list

   for(list){

      bservice.select(list);

   }

3. 全局表

   数据变更比较少的基于全局应用的表

4. 做字段冗余（空间换时间的做法）
   订单表。 商家id  商家名称
   商家名称变更- 定时任务、任务通知

### 跨分片数据排序分页

### 唯一主键问题

用自增id做主键

UUID 性能比较低

snowflake 

mongoDB 

zookeeper 

数据库表



### 分布式事务问题

多个数据库表之间保证原子性  性能问题； 互联网公司用强一致性分布式事务比较少

 

分库分表最难的在于业务的复杂度； 

前提： 水平分表的前提是已经存在大量的业务数据。而这个业务数据已经渗透到了各个应用节点

 

# 如何权衡当前公司的存储需要优化

1．      提前规划（主键问题解决、 join问题）

2．      当前数据单表超过1000W、每天的增长量持续上升

 

# Mysql的主从

**数据库的版本5.7版本**

**安装以后文件对应的目录**

mysql的数据文件和二进制文件： /var/lib/mysql/

mysql的配置文件： /etc/my.cnf

mysql的日志文件： /var/log/mysql.log

 

## 140 为master

1. 创建一个用户’repl’,并且允许其他服务器可以通过该用户远程访问master，通过该用户去读取二进制数据，实现数据同步
   Create user repl identified by ‘repl； repl用户必须具有REPLICATION SLAVE权限，除此之外其他权限都不需要
   GRANT REPLICATION SLAVE ON *.* TO ‘repl’@’%’ IDENTIFIED BY ‘repl’ ; 

2. 修改140 my.cnf配置文件，在[mysqld] 下添加如下配置
   log-bin=mysql-bin //启用二进制日志文件
   server-id=130 服务器唯一ID 

3. 重启数据库 systemctl restart mysqld 

4. 登录到数据库，通过show master status  查看master的状态信息

## 142 为slave

1. 修改142 my.cnf配置文件， 在[mysqld]下增加如下配置
   server-id=132  服务器id，唯一

   relay-log=slave-relay-bin

   relay-log-index=slave-relay-bin.index

   read_only=1

2. 重启数据库： systemctl restart mysqld

3. 连接到数据库客户端，通过如下命令建立同步连接
   change master to master_host=’192.168.11.140’, master_port=3306,master_user=’repl’,master_password=’repl’,**master_log_file=’mysql-bin.000001’,master_log_pos=0;**
   红色部分从master的show master status可以找到对应的值，不能随便写。

4. 执行 start slave

5. show slave status\G;查看slave服务器状态，当如下两个线程状态为yes，表示主从复制配置成功
   **Slave_IO_Running=Yes**
   **Slave_SQL_Running=Yes**

## 主从同步的原理

![1553617853649](..\image\Mysql主从同步.png)

> 1. master记录二进制日志。在每个事务更新数据完成之前，master在二日志记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务   
> 2. slave将master的binary   log拷贝到它自己的中继日志。首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，然后开始binlog dump process。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志   
> 3. SQL线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致   

 

binlog： 用来记录mysql的数据更新或者潜在更新（update xxx where id=x effect row 0）;

文件内容存储：/var/lib/mysql

 

mysqlbinlog --base64-output=decode-rows -v mysql-bin.000001  查看binlog的内容

 

## binlog的格式

**statement** **： 基于sql语句的模式。update table set name =””; effect row 1000； uuid、now() other function**

row： 基于行模式; 存在1000条数据变更；  记录修改以后每一条记录变化的值

mixed: 混合模式，由mysql自动判断处理

修改binlog_formater,通过在mysql客户端输入如下命令可以修改

set global binlog_format=’row/mixed/statement’;

或者在vim /etc/my.cnf  的[mysqld]下增加binlog_format=‘mixed’

 

主从同步的延时问题

### 主从同步延迟是怎么产生的

1. 当master库tps比较高的时候，产生的DDL数量超过slave一个sql线程所能承受的范围，或者slave的大型query语句产生锁等待

2. 网络传输： bin文件的传输延迟

3. 磁盘的读写耗时：文件通知更新、磁盘读取延迟、磁盘写入延迟

### 解决方案

1. 在数据库和应用层增加缓存处理，优先从缓存中读取数据

2. 减少slave同步延迟，可以修改slave库sync_binlog属性； 
   sync_binlog=0  文件系统来调度把binlog_cache刷新到磁盘
   sync_binlog=n  

3. 增加延时监控
   Nagios做网络监控
   mk-heartbeat

 











1.  



关系型数据库和NoSQL

非关系型数据库： key-value： redis 、memcache ； 面向文档： mongoDB ;面向列： HBase

 

数据切分

 

mycat、 TDDL、 Sharding-JDBC、cobar

 

 

# Mycat

Mycat是什么    **仅路由，不处理**



1. Mycat 全局序列号

## Mycat中的核心概念及配置文件分析

###  Mycat rule.xml 分片规则

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mycat:rule SYSTEM "rule.dtd">
<mycat:rule xmlns:mycat="http://io.mycat/">
	<tableRule name="rule1">
		<rule>
			<columns>id</columns>
			<algorithm>func1</algorithm>
		</rule>
	</tableRule>

	<tableRule name="rule2">
		<rule>
			<columns>user_id</columns>
			<algorithm>func1</algorithm>
		</rule>
	</tableRule>

	<tableRule name="sharding-by-intfile">
		<rule>
			<columns>sharding_id</columns>
			<algorithm>hash-int</algorithm>
		</rule>
	</tableRule>
	<tableRule name="auto-sharding-long">
		<rule>
			<columns>id</columns>
			<algorithm>rang-long</algorithm>
		</rule>
	</tableRule>
	<tableRule name="mod-long">
		<rule>
			<columns>id</columns>
			<algorithm>mod-long</algorithm>
		</rule>
	</tableRule>
	<tableRule name="sharding-by-murmur">
		<rule>
			<columns>id</columns>
			<algorithm>murmur</algorithm>
		</rule>
	</tableRule>
	<tableRule name="crc32slot">
		<rule>
			<columns>id</columns>
			<algorithm>crc32slot</algorithm>
		</rule>
	</tableRule>
	<tableRule name="sharding-by-month">
		<rule>
			<columns>create_time</columns>
			<algorithm>partbymonth</algorithm>
		</rule>
	</tableRule>
	<tableRule name="latest-month-calldate">
		<rule>
			<columns>calldate</columns>
			<algorithm>latestMonth</algorithm>
		</rule>
	</tableRule>
	
	<tableRule name="auto-sharding-rang-mod">
		<rule>
			<columns>id</columns>
			<algorithm>rang-mod</algorithm>
		</rule>
	</tableRule>
	
	<tableRule name="jch">
		<rule>
			<columns>id</columns>
			<algorithm>jump-consistent-hash</algorithm>
		</rule>
	</tableRule>

	<function name="murmur"
		class="io.mycat.route.function.PartitionByMurmurHash">
		<property name="seed">0</property><!-- 默认是0 -->
		<property name="count">2</property><!-- 要分片的数据库节点数量，必须指定，否则没法分片 -->
		<property name="virtualBucketTimes">160</property><!-- 一个实际的数据库节点被映射为这么多虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160倍 -->
		<!-- <property name="weightMapFile">weightMapFile</property> 节点的权重，没有指定权重的节点默认是1。以properties文件的格式填写，以从0开始到count-1的整数值也就是节点索引为key，以节点权重值为值。所有权重值必须是正整数，否则以1代替 -->
		<!-- <property name="bucketMapPath">/etc/mycat/bucketMapPath</property> 
			用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个属性，会把虚拟节点的murmur hash值与物理节点的映射按行输出到这个文件，没有默认值，如果不指定，就不会输出任何东西 -->
	</function>

	<function name="crc32slot"
			  class="io.mycat.route.function.PartitionByCRC32PreSlot">
	</function>
	<function name="hash-int"
		class="io.mycat.route.function.PartitionByFileMap">
		<property name="mapFile">partition-hash-int.txt</property>
	</function>
	<function name="rang-long"
		class="io.mycat.route.function.AutoPartitionByLong">
		<property name="mapFile">autopartition-long.txt</property>
	</function>
	<function name="mod-long" class="io.mycat.route.function.PartitionByMod">
		<!-- how many data nodes -->
		<property name="count">3</property>
	</function>

	<function name="func1" class="io.mycat.route.function.PartitionByLong">
		<property name="partitionCount">8</property>
		<property name="partitionLength">128</property>
	</function>
	<function name="latestMonth"
		class="io.mycat.route.function.LatestMonthPartion">
		<property name="splitOneDay">24</property>
	</function>
	<function name="partbymonth"
		class="io.mycat.route.function.PartitionByMonth">
		<property name="dateFormat">yyyy-MM-dd</property>
		<property name="sBeginDate">2015-01-01</property>
	</function>
	
	<function name="rang-mod" class="io.mycat.route.function.PartitionByRangeMod">
        	<property name="mapFile">partition-range-mod.txt</property>
	</function>
	
	<function name="jump-consistent-hash" class="io.mycat.route.function.PartitionByJumpConsistentHash">
		<property name="totalBuckets">3</property>
	</function>
</mycat:rule>

```

### Mycat server.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mycat:server SYSTEM "server.dtd">
<mycat:server xmlns:mycat="http://io.mycat/">
	<system>
	<property name="nonePasswordLogin">0</property> <!-- 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户-->
	<property name="useHandshakeV10">1</property>
	<property name="useSqlStat">0</property>  <!-- 1为开启实时统计、0为关闭 -->
	<property name="useGlobleTableCheck">0</property>  <!-- 1为开启全加班一致性检测、0为关闭 -->

		<property name="sequnceHandlerType">2</property>
	<property name="subqueryRelationshipCheck">false</property> <!-- 子查询中存在关联查询的情况下,检查关联字段中是否有分片字段 .默认 false -->
      <!--  <property name="useCompression">1</property>--> <!--1为开启mysql压缩协议-->
        <!--  <property name="fakeMySQLVersion">5.6.20</property>--> <!--设置模拟的MySQL版本号-->
	<!-- <property name="processorBufferChunk">40960</property> -->
	<!-- 
	<property name="processors">1</property> 
	<property name="processorExecutor">32</property> 
	 -->
        <!--默认为type 0: DirectByteBufferPool | type 1 ByteBufferArena | type 2 NettyBufferPool -->
		<property name="processorBufferPoolType">0</property>
		<!--默认是65535 64K 用于sql解析时最大文本长度 -->
		<!--<property name="maxStringLiteralLength">65535</property>-->
		<!--<property name="sequnceHandlerType">0</property>-->
		<!--<property name="backSocketNoDelay">1</property>-->
		<!--<property name="frontSocketNoDelay">1</property>-->
		<!--<property name="processorExecutor">16</property>-->
		<!--
			<property name="serverPort">8066</property> <property name="managerPort">9066</property> 
			<property name="idleTimeout">300000</property> <property name="bindIp">0.0.0.0</property> 
			<property name="frontWriteQueueSize">4096</property> <property name="processors">32</property> -->
		<!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志-->
		<property name="handleDistributedTransactions">0</property>
		
			<!--
			off heap for merge/order/group/limit      1开启   0关闭
		-->
		<property name="useOffHeapForMerge">1</property>

		<!--
			单位为m
		-->
        <property name="memoryPageSize">64k</property>

		<!--
			单位为k
		-->
		<property name="spillsFileBufferSize">1k</property>

		<property name="useStreamOutput">0</property>

		<!--
			单位为m
		-->
		<property name="systemReserveMemorySize">384m</property>


		<!--是否采用zookeeper协调切换  -->
		<property name="useZKSwitch">false</property>

		<!-- XA Recovery Log日志路径 -->
		<!--<property name="XARecoveryLogBaseDir">./</property>-->

		<!-- XA Recovery Log日志名称 -->
		<!--<property name="XARecoveryLogBaseName">tmlog</property>-->
		<!--如果为 true的话 严格遵守隔离级别,不会在仅仅只有select语句的时候在事务中切换连接-->
		<property name="strictTxIsolation">false</property>
		
		<property name="useZKSwitch">true</property>
		
	</system>
	
	<!-- 全局SQL防火墙设置 -->
	<!--白名单可以使用通配符%或着*-->
	<!--例如<host host="127.0.0.*" user="root"/>-->
	<!--例如<host host="127.0.*" user="root"/>-->
	<!--例如<host host="127.*" user="root"/>-->
	<!--例如<host host="1*7.*" user="root"/>-->
	<!--这些配置情况下对于127.0.0.1都能以root账户登录-->
	<!--
	<firewall>
	   <whitehost>
	      <host host="1*7.0.0.*" user="root"/>
	   </whitehost>
       <blacklist check="false">
       </blacklist>
	</firewall>
	-->

	<user name="root" defaultAccount="true">
		<property name="password">root</property>
		<property name="schemas">TESTDB</property>
		
		<!-- 表级 DML 权限设置 -->
		<!-- 		
		<privileges check="false">
			<schema name="TESTDB" dml="0110" >
				<table name="tb01" dml="0000"></table>
				<table name="tb02" dml="1111"></table>
			</schema>
		</privileges>		
		 -->
	</user>

	<user name="user">
		<property name="password">user</property>
		<property name="schemas">TESTDB</property>
		<property name="readOnly">true</property>
	</user>

</mycat:server>

```

### Mycat schema.xml

Schema.xml 作为 MyCat 中重要的配置文件之一，管理着 MyCat 的逻辑库、表、分片规则、DataNode 以
及 DataSource。弄懂这些配置

```xml
<?xml version="1.0"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">

	<schema name="TESTDB" checkSQLschema="false" sqlMaxLimit="100">
		<!-- auto sharding by id (long) -->
		<table name="travelrecord" dataNode="dn1,dn2,dn3" rule="auto-sharding-long" />

		<!-- global table is auto cloned to all defined data nodes ,so can join
			with any table whose sharding node is in the same data node -->
		<table name="company" primaryKey="ID" type="global" dataNode="dn1,dn2,dn3" />
		<table name="goods" primaryKey="ID" type="global" dataNode="dn1,dn2" />
		<!-- random sharding using mod sharind rule -->
		<table name="hotnews" primaryKey="ID" autoIncrement="true" dataNode="dn1,dn2,dn3"
			   rule="mod-long" />
		<!-- <table name="dual" primaryKey="ID" dataNode="dnx,dnoracle2" type="global"
			needAddLimit="false"/> <table name="worker" primaryKey="ID" dataNode="jdbc_dn1,jdbc_dn2,jdbc_dn3"
			rule="mod-long" /> -->
		<table name="employee" primaryKey="ID" dataNode="dn1,dn2"
			   rule="sharding-by-intfile" />
		<table name="customer" primaryKey="ID" dataNode="dn1,dn2"
			   rule="sharding-by-intfile">
			<childTable name="orders" primaryKey="ID" joinKey="customer_id"
						parentKey="id">
				<childTable name="order_items" joinKey="order_id"
							parentKey="id" />
			</childTable>
			<childTable name="customer_addr" primaryKey="ID" joinKey="customer_id"
						parentKey="id" />
		</table>
		<!-- <table name="oc_call" primaryKey="ID" dataNode="dn1$0-743" rule="latest-month-calldate"
			/> -->
	</schema>
	<!-- <dataNode name="dn1$0-743" dataHost="localhost1" database="db$0-743"
		/> -->
	<dataNode name="dn1" dataHost="localhost1" database="db1" />
	<dataNode name="dn2" dataHost="localhost1" database="db2" />
	<dataNode name="dn3" dataHost="localhost1" database="db3" />
	<!--<dataNode name="dn4" dataHost="sequoiadb1" database="SAMPLE" />

    
	<dataHost name="localhost1" maxCon="1000" minCon="10" balance="0"
			  writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
		<heartbeat>select user()</heartbeat>

		<!-- can have multi write hosts -->
		<writeHost host="hostM1" url="localhost:3306" user="root"
				   password="123456">
			<!-- can have multi read hosts -->
			<readHost host="hostS2" url="192.168.1.200:3306" user="root" password="xxx" />
		</writeHost>
    
		<writeHost host="hostS1" url="localhost:3316" user="root"
				   password="123456" />
		<!-- <writeHost host="hostM2" url="localhost:3316" user="root" password="123456"/> -->
    
	</dataHost>

	<!--
		<dataHost name="sequoiadb1" maxCon="1000" minCon="1" balance="0" dbType="sequoiadb" dbDriver="jdbc">
		<heartbeat> 		</heartbeat>
		 <writeHost host="hostM1" url="sequoiadb://1426587161.dbaas.sequoialab.net:11920/SAMPLE" user="jifeng" 	password="jifeng"></writeHost>
		 </dataHost>

	  <dataHost name="oracle1" maxCon="1000" minCon="1" balance="0" writeType="0" 	dbType="oracle" dbDriver="jdbc"> <heartbeat>select 1 from dual</heartbeat>
		<connectionInitSql>alter session set nls_date_format='yyyy-mm-dd hh24:mi:ss'</connectionInitSql>
		<writeHost host="hostM1" url="jdbc:oracle:thin:@127.0.0.1:1521:nange" user="base" 	password="123456" > </writeHost> </dataHost>

		<dataHost name="jdbchost" maxCon="1000" 	minCon="1" balance="0" writeType="0" dbType="mongodb" dbDriver="jdbc">
		<heartbeat>select 	user()</heartbeat>
		<writeHost host="hostM" url="mongodb://192.168.0.99/test" user="admin" password="123456" ></writeHost> </dataHost>

		<dataHost name="sparksql" maxCon="1000" minCon="1" balance="0" dbType="spark" dbDriver="jdbc">
		<heartbeat> </heartbeat>
		 <writeHost host="hostM1" url="jdbc:hive2://feng01:10000" user="jifeng" 	password="jifeng"></writeHost> </dataHost> -->

	<!-- <dataHost name="jdbchost" maxCon="1000" minCon="10" balance="0" dbType="mysql"
		dbDriver="jdbc"> <heartbeat>select user()</heartbeat> <writeHost host="hostM1"
		url="jdbc:mysql://localhost:3306" user="root" password="123456"> </writeHost>
		</dataHost> -->
</mycat:schema>
```

#### 标签

schema 逻辑库

table 逻辑表

dataNode 数据节点

dataHost host配置

## 实战演练

### $ 的使用

查询：分片key 、非分片key（mycat会缓存）    多分片方式？？？？

数据冗余

### 单库大表拆分

```xml
<!-- select * from db1.table where  逻辑库-->
<!-- checkSQLschema 把sql语句表示 schema 的字符去掉-->
<schema name="TESTDB" checkSQLschema="false" sqlMaxLimit="100">	
	<table name="company" subTables="company$1-3" dataNode="dn1" rule="mod-long" /> <!-- 逻辑表 -->
</schema>


<dataNode name="dn1" dataHost="localhost1" database="db1" /> <!-- 数据节点-->

<!-- host 配置-->
<dataHost name="localhost1" maxCon="1000" minCon="10" balance="0"
		writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
	<heartbeat>select user()</heartbeat>
	<writeHost host="hostS1" url="localhost:3316" user="root" password="123456" />   
</dataHost>
```

数据库操作

\#insert into company(id,name) values(6,'a');

explain select * from company where name='c'





### 跨库分表

```xml
<!-- select * from db1.table where  逻辑库-->
<schema name="TESTDB" checkSQLschema="false" sqlMaxLimit="100">	
	<table name="company" subTables="company$1-3" dataNode="dn1" rule="mod-long" /> <!-- 逻辑表 -->
    <!-- rule 分片规则 -->
    <table name="records" dataNode="dn1,dn2,dn3" rule="mod-long" /> <!-- 逻辑表 -->
</schema>

<!-- database 实际数据库名-->
<dataNode name="dn1" dataHost="localhost1" database="db1" /> <!-- 数据节点-->
<dataNode name="dn2" dataHost="localhost1" database="db2" /> <!-- 数据节点-->
<dataNode name="dn3" dataHost="localhost1" database="db3" /> <!-- 数据节点-->

<!-- host 配置-->
<dataHost name="localhost1" maxCon="1000" minCon="10" balance="0"
		writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
	<heartbeat>select user()</heartbeat>
	<writeHost host="hostS1" url="localhost:3316" user="root" password="123456" />   
</dataHost>
```



### 读写分离

 ```xml
<!-- select * from db1.table where  逻辑库-->
<schema name="TESTDB" checkSQLschema="false" sqlMaxLimit="100" dataNode="dn1"/>	

<dataNode name="dn1" dataHost="localhost1" database="db1" /> <!-- 数据节点-->

<!-- host 配置 -->
<dataHost name="localhost1" maxCon="1000" minCon="10" balance="0"
     writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
  <heartbeat>show slave status</heartbeat>
  <writeHost host="hostM1" url="localhost:3306" user="root" password="root">
    <readHost host="hostS1" url="192.168.1.200:3306" user="root" password="root" />
  </writeHost>
</dataHost>
<!--另一种方式 双主策略-->
<dataHost name="localhost1" maxCon="1000" minCon="10" balance="0"
     writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
  <heartbeat>show slave status</heartbeat>
  <writeHost host="hostM1" url="localhost:3306" user="root"
           password="root">
  </writeHost>
   <writeHost host="hostS1" url="192.168.1.200:3306" user="root"
           password="root" />

</dataHost>

<!--
  <dataHost name="sequoiadb1" maxCon="1000" minCon="1" balance="0" dbType="sequoiadb" dbDriver="jdbc">
  <heartbeat> 		</heartbeat>
   <writeHost host="hostM1" url="sequoiadb://1426587161.dbaas.sequoialab.net:11920/SAMPLE" user="jifeng" 	password="jifeng"></writeHost>
   </dataHost>

   <dataHost name="oracle1" maxCon="1000" minCon="1" balance="0" writeType="0" 	dbType="oracle" dbDriver="jdbc"> <heartbeat>select 1 from dual</heartbeat>
  <connectionInitSql>alter session set nls_date_format='yyyy-mm-dd hh24:mi:ss'</connectionInitSql>
  <writeHost host="hostM1" url="jdbc:oracle:thin:@127.0.0.1:1521:nange" user="base" 	password="123456" > </writeHost> </dataHost>

  <dataHost name="jdbchost" maxCon="1000" 	minCon="1" balance="0" writeType="0" dbType="mongodb" dbDriver="jdbc">
  <heartbeat>select 	user()</heartbeat>
  <writeHost host="hostM" url="mongodb://192.168.0.99/test" user="admin" password="123456" ></writeHost> </dataHost>

  <dataHost name="sparksql" maxCon="1000" minCon="1" balance="0" dbType="spark" dbDriver="jdbc">
  <heartbeat> </heartbeat>
   <writeHost host="hostM1" url="jdbc:hive2://feng01:10000" user="jifeng" 	password="jifeng"></writeHost> </dataHost> -->

<!-- <dataHost name="jdbchost" maxCon="1000" minCon="10" balance="0" dbType="mysql"
  dbDriver="jdbc"> <heartbeat>select user()</heartbeat> <writeHost host="hostM1"
  url="jdbc:mysql://localhost:3306" user="root" password="123456"> </writeHost>
  </dataHost> -->
 ```



### Mycat 架构

![1553650849880](..\image\Mycat架构.png)

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 