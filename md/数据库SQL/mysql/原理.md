REPEAT(str,count)  返回一个由字符串str重复count次数组成的字符串。 

Latin 编码



MVCC  两个隐藏列行创建时间，过期时间 ，存储系统版本号，行删除表标识，只工作于低两级的隔离级别

## InnoDB 存储引擎

ibdata1（页 ，offset）

页，基于页管理









参数 innodb_flush_log_at_trx_commit 用于控制重做日志刷新到磁盘的策略，默认为 1，表示事务提交时必须调用一次 fsync 操作， 0  仅在 master thread 中完成















一致性读（consisted read）

full purge

10%~70%



auto_increment  在插入 null  值  时会自增数值，指定值不会自增



change buffer   非唯一索引（ ）

my.cnf

sql_mode



### 架构

#### 后台线程

负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据



* master thread



* io thread   

AIO   io  请求回调

> innodb_file_io_threads (旧)
>
> write thread 和 read thread
>
> innodb_read_io_threads
>
> innodb_write_io_threads
>
> show variables like 'xxx';

* purge thread



* page cleaner thread  脏页刷新



#### 内存

##### 缓冲池

索引页、数据页、undo页、插入缓冲、自适应哈希索引、innodb 存储的锁信息、数据字典信息

innodb_additional_mem_pool_size

innodb_buffer_pool_instances

information_schema.INNODB_BUFFER_POOL_STATS

LRU List、Free List 和 Flush List 管理页

LRU 变种  （避免页频繁）  引入  midpoint

midpoint insertion strategy       innodb_old_blocks_pct 设置 midpoint 位置 百分比

LRU List 5/8

midpoint 后   old 列表

midpoint 前   new 列表    页为最活跃的热点数据



 innodb_old_blocks_time 表示页读取到 mid 位置后需要等待多久才会被加入到 LRU 列表的热端

> set global innodb_old_blocks_time=1000
>
> set global innodb_old_blocks_pct=37

page made young

page not  made young

> show engine innodb status;
>
> 观察 LRU 和 free 列表的使用情况和运行状态

压缩页

16KB 压缩为 1KB, 4KB, 8KB

非 16 KB 的页，通过 unzip_LRU 列表进行管理

LRU 中的页包含了 unzip_LRU 列表中的页

unzip_LRU 是怎样从缓冲池中分配内存的呢？

information,INNODB_BUFFER_PAGE_LRU

FLUSH 列表中的页为脏页列表，CHECKPOINT 



##### 重做日志缓冲

innodb_log_buffer_size 调整重做日志缓冲大小

InnoDB 存储引擎首先将重做日志信息先放入到这个缓冲区，然后按一定频率（一般为每一秒钟）将其刷新到重做日志文件。

重做日志缓冲中的内容刷新到外部磁盘的重做日志文件中，有下列情况：

* Master Thread 每一秒将重做日志缓冲刷新到重做日志文件
* 每个事务提交时会将重做日志缓冲刷新到重做日志文件
* 当重做日志缓冲池剩余空间小于 1/2 时，重做日志缓冲刷新到重做日志文件



重做日志 redo log（顺序）和 undo log （随机）

 redo log：保证事务持久性

undo log：帮助事务回滚及 MVCC 功能

fsync 操作，用于确保重做日志写入磁盘，效率取决于磁盘的性能

磁盘的性能决定事务提交的功能



* 额外内存池

innodb 存储引擎对内存管理是通过内存堆（heap）的方式进行的。

在对一些数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池进行申请。

缓冲池中的帧缓冲（frame buffer）

缓冲控制对象：记录一些诸如 LRU、锁、等待等信息，对象内存需要从额外内存池中申请



### Checkpoint 技术

缓冲池的设计目的是为了协调 CPU 速度与磁盘速度的鸿沟，因此页操作首先都是在缓冲池中完成

Write Ahead Log 策略，事务提交时，先写重做日志再修改页

Checkpoint 技术目的是解决一下问题：

* 缩短数据库恢复时间
* 缓冲池不够用是，将脏页刷新到磁盘
* 重做日志不可用时，刷新脏页



* sharp checkpoint：发生在数据库关闭时将所有的脏页都刷新回磁盘，这是默认的工作方式 ，即innodb_fast_shutdown = 1

* fuzzy checkpoint：只刷新一部分脏页，而不是刷新所有的脏页会磁盘

  * Master Thread Checkpoint

    * 异步

  * FLUSH_LRU_LIST Checkpoint

    * InnoDB 引擎需要保证 LRU 列表中存在一定的空闲页可供使用，若不足会将 LRU 列表尾端页移除，若有脏页会进行 Checkpoint
    * MySQL 5.6+ 即 innodb 1.2.x+，这个检查会在单独的 Page Cleaner 线程进行， 通过 innodb_lru_scan_depth 控制 LRU 列表中可用页数量，默认为 1024

  * Async/Sync Flush Checkpoint

    * 在重做日志文件不可用的情况，这时需要强制将一些页刷新回磁盘，从脏页列表中选取页

    * 重做日志的 LSN 记为 redo_lsn，将已经刷新回磁盘最新页的 LSN 记为 checkpoint_lsn，则有

      ```text
      checkpoint_age = redo_lsn - checkpoint_lsn
      # 再定义以下的变量：
      async_water_mark = 75% * total_redo_log_file_size
      sync_water_mark = 90% * total_redo_log_file_size
      ```

      * checkpoint_age < async_water_mark， 不需要刷新任何脏页到磁盘
      * async_water_mark <  checkpoint_age < sync_water_mark，触发 Async Flush，刷新 Flush 列表一定量脏页回磁盘，直到满足第一种情况
      * checkpoint_age > sync_water_mark，很少发生，触发 Sync Flush，刷新 Flush 列表一定量脏页回磁盘，直到满足第一种情况

  * Dirty Page too much Checkpoint

    * 脏页过多，强制进行 checkpoint
    * 由 innodb_max_dirty_pages_pct 控制

LSN 标识重做日志 

checkpoint 刷新到磁盘的最新位置



### Master Thread 工作方式

loop,backgroud loop，suspend loop

full purge

buf_get_modified_ratio_pct

合并插入缓冲  innodb_io_capacity

innodb_adaptive_flushing

buf_flush_get_desired_flush_rate

### 关键特性

#### 插入缓冲（insert  buffer）

##### insert buffer

对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入；若不在，则先放入到一个 insert buffer 对象中。然后以一定的频率和情况进行 insert buffer 和辅助索引页子节点的 merge（合并）操作，这是通常能将多个插入合并到一个操作中（因为在一个索引页中）

使用条件：索引是辅助索引，索引不是唯一的

> show engine innodb status;

问题：写密集情况，占用过多缓冲池内存

IBUF_POOL_SIZE_PER_MAX_SIZE



##### Change Buffer

insert buffer 的升级

> 页（space，offset/page_no）
>
> Insert Buffer 非叶子节点中的 search key：
>
> space  待插入记录所在表空间 id  4字节
>
> marker  1字节，用于兼容老版本 Insert Buffer
>
> offset  页所在的偏移量 4字节
>
> Insert Buffer 叶子节点：
>
> space、marker、offset 同上
>
> metadata  4字节
>
> secondary index record
>
>

Insert Buffer

Delete Buffer update 第一个过程，将记录标记为删除   delete mark

Purge Buffer update 第二个过程，将记录真正删除 



innodb_change_buffering 开启各种 buffer 选项

inserts、deletes、purges、changes（inserts 和 deletes）、all、none。

innodb_change_buffer_max_size

merged operation

discarded operation：当 change buffer 发生 merge 时，表已经被删除，此时无需将记录 merge 到辅助索引中



共享表空间 ibdata1



**Insert Buffer Bitmap**



##### Merge Insert Buffer

* 场景
  * 辅助索引页被读取到缓冲池时
    * select 查询
  * Insert Buffer Bitmap 页追踪到该辅助索引页已无可用空间时(小于 1/32 页)
  * Master Thread（按一定频率 Merge Insert Buffer）
    * srv_innodb_io_capacity 的百分比决定真正合并多少个辅助索引页



#### 双写（doublewrite）

应对部分写失效问题

当写入失效发生时，先通过页的副本还原该页，再进行重做

两部分组成 ，2MB：

* 内存中的  doublewrite buffer

  脏页刷新不直接写磁盘，由 memcpy 拷贝到内存中的  doublewrite buffer，之后分两次，每次1MB顺序写入共享表空间的物理磁盘上，然后马上调用 fsync 同步磁盘，避免缓冲写带来的问题

* 





#### 自适应哈希索引



#### 异步 IO

innodb_user_native_aio

#### 刷新邻接页

flush neighbor page

当刷新一个脏页是， innodb 会检测该页所在区（extend）的所有页，如果是脏页，那么一起进行刷新

innodb_flush_neighbors   固态盘设 0 关闭，机械盘可开启



### 启动、关闭与恢复

innodb_fast_shutdown

0  完成所有的 full purge 和 merge insert buffer，将所有脏页刷新回磁盘

1 默认值，不完成 full purge 和 merge insert buffer，刷新一些脏页

2 不完成 full purge 和 merge insert buffer，也不将缓冲池脏页刷新回磁盘，将日志写入日志文件。这样不会有任何事务丢失，下次 mysql 启动时，会进行恢复操作（recovery）



innodb_force_recovery:1~6



## 文件

参数文件

> show variables;
>
> GLOBLE_VALIABLES
>
> 静态参数
>
> 动态参数
>
> set @@global.xxx|@@session.xxx

日志文件

> 错误日志（error log）
>
> **二进制日志（binlog）**:用于恢复，主从复制(slave 或 standby)，审计，默认不开启
>
> 慢查询日志（slow query log）
>
> long_query*   log_output
>
> mysqldumpslow
>
> 查询日志（log）

* 二进制日志（binlog）

show master status;

show binlog events in 'mysqld.xxx';

mysqlbinlog

log-bin[=name]

参数：

max_binlog_size 单个二进制日志文件的最大值

binlog_cache_size 缓存未提交二进制日志的缓冲池大小，基于会话 session

sync_binlog = [N] 每写缓冲多少次就同步到磁盘，1 表示同步写盘（这是不用操作系统缓冲），默认 0，为1 时需考虑 日志和数据文件同步问题  ，  innodb_support_xa  二阶段提交

binlog-do-db,binlog-ignore-db 需要写入或忽略哪些库的日志

log-slave-update 主从复制相关

binlog_format：STATEMENT,ROW,MIXED



套接字文件

pid文件

表结构定义文件   .frm



### innodb 存储引擎文件

#### 表空间文件

innodb 采用将存储的数据按表空间（tablespace）进行存放的设计

默认配置下有一个初始大小为 10MB ，名为 ibdata1 的文件

通过 innodb_data_file_path 设置表空间文件，所有基于 innodb存储引擎的表的数据都会记录到该共享空间

由 innodb_data_file_path 用户可通过多个文件组成一个表空间



设置 innodb_file_per_table=on，用户可以将每个基于 innodb 的表产生一个独立表空间（表名.ibd），这些表空间文件仅存储该表数据，索引和插入缓冲 BITMAP等信息，其余信息（回滚（undo）信息，插入缓冲索引页，系统事务信息，二次写缓冲（doublewrite buffer）等）存储在默认的共享表空间



#### 重做日志文件

记录每个页（Page）更改的物理情况

每个 innodb 至少有 1 个重做日志文件组（group），每个文件组下至少有两个重做日志文件，如默认的 ib_logfile0 和ib_logfile1

可设置多个镜像日志组（mirrored log groups）将不同的文件组放在不同的磁盘上，提高重做日志的高可用

循环写入（ribbon round）写到底就切换

> innodb_log_file_size
>
> innodb_log_file_in_group
>
> innodb_mirrored_log_groups
>
> innodb_log_group_home_dir
>
> innodb_flush_log_at_trx_commit



## 表

innodb中，表都是根据主键顺序组织存放的，这种表称为索引组织表（index organized table）

若没显式定义主键，按如下方式选择或创建主键

* 首先判断表中是否有非空的唯一索引（unique not null），如果有，则该列即为主键，若有多个则选择 定义的第一个（主键的选择根据的是定义索引的顺序，而不是建表时列的顺序）
* 如果不符合上述条件，innodb 存储引擎将自动创建一个 6 字节大小的指针

_rowid 表示主键列，只适合单列为主键



### InnoDB  逻辑存储结构

#### 表空间

表空间（tablespace）由段（segment）、区（extent）、页（page）/块（block）组成

> oracle  自动段空间管理（ASSM）

#### 区

区（extent）是由连续页组成的空间，**在任何情况下每个区的大小都为 1MB**。为了保证区中页的连续性， innodb 一次从磁盘申请 4~5 个区。默认情况下，innodb 页的大小为 16 KB,即一个区中一共有 64 个连续的页

innodb 1.0.x 引入压缩页，页大小可通过 KEY_BLOCK_SIZE 设置为 2KB、4 KB、8KB，对应每个区的页数为 512,256,128

innodb 1.2.x 新增 innodb_page_size 设置页大小



表空间默认大小 96 KB，因每个段开始时先用 32 个页大小的碎片页（fragment page）来存放数据，用完时才到 64 个连续页的申请

py_innodb_page_info 工具查看表空间

#### 页

 innodb_page_size 

常见的页类型有：
□ 数据页（B-tree Node）
□ undo页（undo Log Page）
□ 系统页（System Page）
□ 事务数据页（Transaction system Page）
□ 插入缓冲位图页（Insert Buffer Bitmap）
□ 插入缓冲空闲列表页（Insert Buffer Free List）
□ 未压缩的二进制大对象页（Uncompressed BLOB Page）
□ 压缩的二进制大对象页（compressed BLOB Page

#### 行

每个页最多允许存放 16KB/2~200行记录，即7992 行记录



### InnoDB 行记录格式

Antelope（Compact 和 Redundant ）

Barracuda（Compressed 和 Dynamic）

PHYSICAL RECORD(OLD/NEW STYLE)

> SHOW TABLE STATUS LIKE 'table_name%'
>
> UltraEdit
>
> hexdump -C -v xxx.ibd > xxx.txt



BLOB，LOB 大对象

varchar 共 65535

行溢出页  Uncompressed BLOB page

CHAR off page

单字节 latin1格式



### InnoDB 数据页结构

https://zhuanlan.zhihu.com/p/141338773

#### File Header（文件头） 38 字节

checksum

页定位的相关信息

![](..\..\image\架构\mysql-file-header.PNG)

![](..\..\image\架构\mysql-page-type.PNG)



#### Page Header（页头） 56 字节



![](..\..\image\架构\mysql-page-header.PNG)



#### Infimun 和 Supremum Records

 每个数据页中有两个虚拟的行记录，用来限定记录的边界。

Infimum记录是比该页中任何主键值都要小的值。
Supremum指比任何可能大的值还要大的值。

这两个值在页创建时被建立，并且在任何情况下不会被删除。在Compact行格式和Redundant行格式下，两者占用的字节数各不相同。  

#### User Records（用户记录，即行记录）

User Record就是实际存储行记录的内容

#### Free Space（空闲空间）

Free Space指的是空闲空间，同样也是个链表数据结构。在一条记录被删除后，该空间会被加入到空闲链表中。

#### Page Directory（页目录）

页目录中存放了记录的相对位置（注意，是页相对位置，而不是偏移量），有些时候这些记录指针称为Slots（槽）或目录槽（Directory Slots）。在InnoDB中并不是每个记录拥有一个槽，InnoDB存储引擎的槽是一个稀疏目录（sparse directory），即一个槽中可能包含多个记录。伪记录Infimum的n_owned值总是为1，记录Supremum的n_owned的取值范围为[1，8]，其他用户记录n_owned的取值范围为[4，8]。当记录被插入或删除时需要对槽进行分裂或平衡的维护操作。

在Slots中记录按照索引键值顺序存放，这样可以利用二叉查找迅速找到记录的指针。

由于页目录是稀疏目录，二叉查找的结果只是一个粗略的结果，因此必须通过recorder header中的next_record来继续查找相关记录。同时，也很好地解释了recorder header中的n_owned值的含义，因为这些记录并不包括在页目录中。

B+树索引本身并不能找到具体的一条记录，只能找到该记录所在的页。数据库把页载入到内存，然后再进行二叉查找。因为二叉查找很快，加上在内存中的查找更快，因此通常可以忽略这部分查找所用的时间。  



#### File Trailer（文件结尾信息） 8 字节

  File Trailer是为了检测页是否已经完整地写入磁盘，只有一个FIL_PAGE_END_LSN部分，占用8字节。前4字节代表该页的checksum值，最后4字节和File Header中的FIL_PAGE_LSN相同。

将这两个值与File Header中的FIL_PAGE_SPACE_OR_CHKSUM和FIL_PAGE_LSN值进行比较，看是否一致（checksum的比较需要通过InnoDB的checksum函数来进行比较，不是简单的等值比较），以此来保证页的完整性。

在默认配置下，每次从磁盘读取一个页就会检测该页的完整性。该检测会有一定的开销，可以通过参数innodb_checksums来开启或关闭页完整性的检查。

MySQL5.6.6版本引进了crc32的checksum算法，该算法性能较高。低版本可能无法读取表中页。若数据库从低版本升级而来，则需要进行mysql_upgrade操作。  



### Named File Formats机制

随着InnoDB的发展，新的页数据结构有时用来支持新的功能特性。比如前面提到的支持表压缩功能，完全的溢出（Off page）大变长字符类型字段的存储。为解决不同版本下页结构兼容性的问题，从InnoDB 1.0.x版本开始，InnoDB存储引Named File Formats机制。

InnoDB存储引擎将1.0.x版本之前的文件格式（file format）定义为Antelope，将这个版本支持的文件格式定义为Barracuda。新的文件格式总是包含于之前的版本的页格式。



  未来版本的InnoDB存储引擎还将引入新的文件格式，此文件格式的名称取自动物的名字，并按照字母排序进行命名。

参数innodb_file_format用来指定文件格式。参数innodb_file_format_check用来检测当前InnoDB存储引擎文件格式的支持度，该值默认为ON，如果出现不支持的文件格式，错误日志文件中一般会有相关的报错。  





### 约束

#### 数据完整性

几乎所有的关系型数据库都提供了约束（constraint）机制。数据完整性一般有以下三种形式：

**实体完整性**

保证表中有一个主键。在InnoDB中，可以通过定义Primary Key或Unique Key约束来保证实体的完整性。还可以通过编写一个触发器来保证数据完整性。

**域完整性**

保证数据每列的值满足特定的条件。在InnoDB中，域完整性可以通过以下几种途径来保证：

- 选择合适的数据类型确保一个数据值满足特定条件。
- 外键（Foreign Key）约束。
- 编写触发器。
- 考虑用DEFAULT约束作为强制域完整性的一个方面。

**参照完整性**

保证两张表之间的关系。InnoDB支持外键，允许用户定义外键以强制参照完整性，也可以通过编写触发器以强制执行。InnoDB提供了以下几种约束：

- Primary Key
- Unique Key
- Foreign Key
- Default
- NOT NULL

#### 约束和索引的区别

Primary Key和Unique Key的约束通常也是创建索引的方法，那约束和索引有什么区别呢？

创建一个唯一索引就创建了一个唯一的约束。约束更是一个逻辑的概念，用来保证数据的完整性。而索引是一个数据结构，既有逻辑上的概念，在数据库中还代表着物理存储的方式，便于快速找到数据。

#### 触发器与约束

触发器的作用是在执行INSERT、DELETE和UPDATE命令之前或之后自动调用SQL命令或存储过程。通过触发器，可以实现如对于传统CHECK约束的支持，物化视图、高级复制、审计等特性。

创建触发器的命令是CREATE TRIGGER，需要Super权限。

一个表最多可以建立6个触发器，即分别为INSERT、UPDATE、DELETE的BEFORE和AFTER各定义一个。BEFORE和AFTER代表触发器发生在每行操作的之前还是之后。当前MySQL数据库只支持FOR EACH ROW的触发方式，不支持像DB2的FOREACH STATEMENT的触发方式。

（似乎很少见到使用触发器的案例，有说法是会影响性能，可维护性差。）

#### 外键约束

外键用来保证参照完整性，MyISAM不支持外键，InnoDB完整支持外键约束。

被引用的表称为父表，引用的表称为子表。外键定义时的ON DELETE和ON UPDATE表示在对父表进行DELETE和UPDATE操作时，对子表所做的操作，可定义的子表操作有：

- CASCADE：表示当父表发生DELETE或UPDATE操作时，对相应的子表中的数据也进行DELETE或UPDATE操作。
- SET NULL：表示当父表发生DELETE或UPDATE操作时，相应的子表中的数据被更新为NULL值，但是子表中相对应的列必须允许为NULL值。
- NO ACTION：表示当父表发生DELETE或UPDATE操作时，抛出错误，不允许这类操作发生。
- RESTRICT：表示当父表发生DELETE或UPDATE操作时，抛出错误，不允许这类操作发生。这个时默认的外键设置。


目前MySQL的外键约束都是即时检查（immediate check），Oracle有一种称为延时检查（deferred check）的外键约束，即在SQL语句运行完成后进行检查。

InnoDB和Microsoft SQL Server在外键建立时会自动地对该列加索引，避免外键列上无索引而导致的死锁问题的产生。而Oracle对于建立外键的列需要用户加索引。

因为MySQL的外键是即时检查的，所以导入数据时会花费大量的时间，对导入的每一行都会进行外键检查。但可以通过参数foreign_key_checks来忽视导入过程的外键检查。

#### 其他约束

参数sql_mode，用来控制对输入数据的校验，如STRICT_TRANS_TABLES表示对于输入数据的合法性进行了约束，而且针对不同的错误，提示的错误内容也都不同。参数sql_mode可设的值有很多，具体可参考MySQL官方手册。

（书中有提到“数据库本身没有对数据的正确性进行约束”，这句话应该不准确，字段数据类型本身就是对数据正确性的约束。）

ENUM，与C语言的枚举一样，如性别类型，规定域的范围只能是male或female





## 索引和算法



磁盘地址  id

文件系统【磁盘，柱面，磁道，扇区】

操作系统 时间局部性，空间局部性     Page

### 什么是索引

索引时帮助高效获取数据的数据结构

索引也可能是一个文件

其他类型：

> Hash   Map
>
> 二叉树
>
> 红黑树

* b+ 树索引（b+ 树索引找出记录所在页载入内存， 再通过  page directory 二叉查找）
* 全文索引
* 哈希索引（innodb 引擎支持自适应，不能人为设置）



* 数据结构和算法
  * 二分查找法
  * 二叉查找树和平衡查找树

B树，每个节点（key,data）二元组

### B+ 树

* 插入操作原理
  * leaf page  
  * index page
* 删除操作原理
  * 填充因子

hexdump 工具    Page Directory（稀疏）

innodb

> idb，以主键为索引来组织数据，叶子存数据
>
> * 聚集索引（clustered index）
>
> 非叶子节点（键，指向数据页偏移量）
>
> 双向链表
>
> * 辅助索引（secondary index），也称非聚集索引（可多个）
>
>   叶子节点除了包含键值以外，每个叶子节点中的索引行还包含了一个书签（bookmark），书签可告诉 innodb 存储引擎那里可以找到与索引相对应的行数据，在 innodb 存储引擎的书签就是相应行数据的聚集索引键
>
> 遍历辅助索引获得指向主键索引的主键，在通过主键索引来找完整的行记录0



> myisam
>
> myi文件，索引 B+ Tree  ，叶子存 myd 地址-，副索引也存地址>
>
> myd文件，表
>
> 非聚集索引







depth，node 多数据

* 为什么用自增 id 作为主键？

- CRUD：自增 id vs UUID

相对于 B+树

自增 id 数据插入总在最右边，（一个一个Page填满），数字比较

UUID 随机插入数据，数据分裂/移动相对频繁，字符串比较



列的离散型：

比例越高，离散性越大

离散性越高，选择性就越好



最左匹配原则

对索引中关键字进行计算（对比），一定是从左往有依次进行，且不可跳过



>
>
> SHOW INDEX FROM table_name;
>
> ANALYSE TABLE  table_name

#### 索引管理

> ALTER TABLE 语法
>
> CREATE /DROP INDEX





### Cardinality

> SHOW INDEX FROM table_name;
>
> analyse table,show table status ,show index, infomation_schema.tables ,infomation_schema.statistics
>
> P222

Cardinality   索引评估参考     更新策略，抽样计算



### B+ 树索引使用



#### 联合索引

单列索引是特殊的联合索引



联合索引列选择原则

1. 经常使用的列优先【最左匹配原则】
2. 离散度越高的列优先【离散度高原则】
3. 宽度小的列优先【最小空间原则】



#### 覆盖索引

覆盖索引 （covering index），即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。优点：辅助索引不包含整行数据记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的 IO操作

辅助索引叶子节点（primary key1，primary key2，...，key1，key2，...）



#### 优化器选择

explain 分析 sql 语句

不使用索引的情况，即全表扫描检索数据， 多出现于范围查找，join 链接 操作

当访问数据占整个表的一部分数据（一般 20%左右），优化器会选择通过聚集索引来查找数据



FORCE INDEX（使用指定索引查询）

索引提示（INDEX HINT）

USE INDEX （给查询提供索引参考）















###　Multi-Read Range（MRR） 优化（MySQL5.6+）



随机访问转化为顺序访问

优化 IO-bound

适用于 range，ref，eq_ref 类型查询



还可以将某些范围查询，拆分为键值对来进行批量的数据查询，可在拆分过程中过滤数据

> SET @@optimizer_switch='mrr=on, mrr_cost_based=off';
>
> mrr_cost_based
>
> mrr
>
> read_rnd_buffer_size 用来控制键值的缓冲区大小



### Index Condition Pushdown（ICP）优化（MySQL5.6+）

执行计划 Extra     Using Index Condition

若支持 Index Condition Pushdown，索引取出时就会进行 where 条件的过滤，再去获取记录，这可提高查询效率



### 哈希算法

除法散列   k mod n

自适应哈希

> show engine innodb status;



### 全文检索（Full-Text search）

倒排索引（inverted index）

辅助表（auxiliary table）

inverted file index{单词，单词所在文档的 ID}

full inverted index{单词，{单词所在文档的 ID，在具体文档中的位置}}

FTS Index Cache

> set global innodb_ft_aux_table='...'

FTS_DOC_ID

information_schema

OPTIMIZE TABLE

FULLTEXT 类型



> SELECT * FROM tbl_name  WHERE MATCH()  AGAINST('');
>
> 语法
>
> WITH QUERY EXPANSION 
>
> IN NATURAL LANGUAGE MODE WITH WITH QUERY EXPANSION
>
> blind query expansion(automatic relevance feedback)



## 锁

innodb 不会使用 gap lock 锁算法

lock （事务 表，页，行）

latch（mutex，rwlock）

## 事务

write ahead log    事务提交时，先写重做日志再修改页

事务的原理机制

* 事务提交
  * 修改内存中事务对应的信息，并且将日志写入重做日志缓冲
  * 调用 fsync 将确保日志都从重做日志缓冲写入磁盘

savepoint 保存点

### 特性 ACID



### 事务实现

事务隔离性由锁来实现

redo log 重做日志，用来保证事务原子性和持久性

undo log 用来保证事务的一致性

redo 恢复提交事务修改的页操作，undo 回滚行记录到某个特定版本

redo 是物理日志，记录页的物理修改操作，undo 是逻辑日志，根据每行记录进行记录

#### redo

重做日志用来实现事务的持久性，即事务 ACID 的 D。由两部分组成：

* 内存中的重做日志缓冲（redo log buffer），易失
* 重做日志文件（redo log file），持久



Force Log at Commit 机制：当事务提交（COMMIT）时，必须先将该事务的所有日志（重做日志）写入到重做日志文件进行持久化，待事务的 COMMIT 操作完成才算完成。



重做日志缓冲（redo log buffer），事务提交成功，会有线程专门清理重做日志



* 重做日志：
  * redo log：保证事务持久性（顺序写）
  * undo log：帮助事务回滚及 MVCC 功能（随机读写）



每次重做日志缓冲（redo log buffer）写入重做日志文件后，innodb 存储引擎都需要调用一次 fsync 操作，因没有使用 O_DIRECT，重做日志缓冲先写入文件系统缓存

fsync 操作：用于确保重做日志写入磁盘，效率取决于磁盘的性能，磁盘的性能决定事务提交的功能



参数 innodb_flush_log_at_trx_commit 用于控制重做日志刷新到磁盘的策略，默认为 1，表示事务提交时必须调用一次 fsync 操作； 0  表示事务提交时不写入重做日志操作，仅在 master thread 中完成；2 表示事务提交时写入重做日志到文件，仅写入文件系统缓存不 fsync 



binlog   POINT-IN-TIME (PIT) 的恢复和主从复制环境的建立



* 二进制日志：一个事务一个日志
  * 在数据库上层产生，任何存储引擎对于数据库的更改都会产生二进制日志，逻辑日志，记录对应 SQL 语句
  * 仅在事务提交完成后进行一次写入

* 重做日志 ：并发，每个事务多个日志条目

  * 在innodb 存储引擎层产生

  * 物理格式日志，记录对于每个页的修改，物理操作日志，在事务进行中不断地被写入

  * log block 日志块 512字节

    日志头 12 字节   日志尾 8 字节 实际可存储日志内容大小 492 字节（512-12-8）

log checkpoint

>
>
> redo log file 前 2KB （4个 512 字节）
>
> log file header 512  
>
> checkpoint1 512 
>
> 空 512  
>
> checkpoint2  512
>
> 只在每个 log group 的 第一个 redo log file 存储，checkpoint 交替使用



> * 重做日志格式：
>   * redo_log_type 重做日志类型
>   * space 表空间 id 
>   * page_no 页偏移量
>   * redo log body 类型不同，内容格式不同
>
> SHOW ENGINE INNODB STATUS;

* LSN(Log   Sequence  Number) 表示事务写入重做日志的字节的总量，表示页已经被刷新到该位置

不仅记录在重做日志，还存在每个页头 FIL_PAGE_LSN

* Log flushed up to 表示刷新到重做日志文件的 LSN

* Last checkpoint at 表示刷新到磁盘的 LSN





恢复：只需恢复 checkpoint 开始的日志部分



#### undo 

undo 存放在数据库内部的一个特殊段（segment），undo 段（undo segment）位于共享表空间内

py_innodb_page_info.py 

执行一个相反操作  insert --- delete    update --- update 回原来

非锁定读取

rollback segment     1024 undo log segment



innodb_undo_directory 设置 rollback segment 文件所在路径

innodb_undo_logs 设置 rollback segment 个数，默认128

innodb_undo_tablespaces 设置构成 rollback segment 文件的数量



purge 线程，一个undo 页 可能存放不同事物的 undo log，purge 操作需要涉及磁盘的离散读取操作

undo 页   使用 < 3/4   可重用



insert undo log 仅事务本身可见，提交后可直接删除不用 purge

update undo log（delete ，update操作） 提供 mvcc



INNODB_TRX_ROLLBACK_SEGMENT

INNODB_TRX_UNDO



#### purge

history list  ->  undo page -> undo log

delete 设置标志 由 purge 处理

innodb_purge_batch_size



#### group commit

事务提交阶段

为保证存储引擎中的事务和二进制日志的一致性(备份及恢复的需要)，二者之间使用了两阶段事务，步骤如下：

* 当事务提交时 InnoDB 存储引擎进行 prepare 操作
* mysql 数据库上层写入二进制日志
  * 这操作完成，就确保了事务的提交
  * fsync 由 sync_binlog 控制
* innodb 存储引擎层将日志写入重做日志文件
  * 修改内存中事务对应的信息，并且将日志写入重做日志缓冲
  * 调用 fsync 将确保日志都从重做日志缓冲写入磁盘
    * fsync 由 innodb_flush_log_at_trx_commit 控制

每个步骤都需要进行一次 fsync 操作才能保证上下文两层数据的一致性

![](..\..\image\架构\mysql-binlog.PNG)



Binary Log Group Commit（BLGC） 步骤：

* Flush 阶段， 将每个事务的二进制日志写入内存中

* Sync 阶段，将内存中的二进制日志刷新到磁盘，若队列中有多个事务，那么进一次 fsync 操纵就完成了二进制日志的写入 ，这就是 BLGC

* Commit 阶段， leader 根据顺序调用存储引擎层事务的提交， innodb 存储引擎本来就支持 group commit，因此修复了原先由于锁 prepare_commit_mutex 导致 group commit 失效的问题 



### 事务控制

START TRANSACTION|BEGIN

COMMIT

ROLLBACK

SAVEPOINT identifier

RELEASE SAVEPOINT identifier

ROLLBACK TO[SAVEPOINT] identifier

SET TRANSACTION



## 备份和恢复

热备 运行时备份    ibbackup  XtraBackup

LVM  写时复制 元数据    快照 （修改问题）

show slave status;

冷备 停机备份

温备



* 逻辑备份

可读文件，存 SQL

> mysqldump --single-transaction
>
> SELECT * INTO OUTFILE
>
> SOURCE
>
> LOAD DATA INFILE
>
> mysqlimport
>
> show full processlist;

foreign_key_check

* 裸文件备份

复制物理文件



备份类型：

* 完全备份

* 增量备份

* 日志备份 备份二进制日志

point-in-time





































































# END